## 多进程
多进程 Multiprocessing 和多线程 threading 类似，用来弥补 threading 的一些劣势（例如GIL）， Python 出了一个 multiprocessing

### 多进程与多线程
使用方法几乎一致
```
import multiprocessing
import threading

def job_t(a,d):
    print('tttt')

def job_p(a,d):
    print('pppp')


t1 = threading.Thread(target=job_t,args=(1,2))
p1 = multiprocessing.Process(target=job_p,args=(1,2))
t1.start()
p1.start()

t1.join()
p1.join()
```
### 进程结果 Queue()
```
import multiprocessing as mp

def job(q):
    res=0
    for i in range(1000):
        res+=i+i**2+i**3
    q.put(res)    #queue

if __name__=='__main__':
    q = mp.Queue()
    p1 = mp.Process(target=job,args=(q,))
    p2 = mp.Process(target=job,args=(q,))
    p1.start()
    p2.start()
    p1.join()
    p2.join()
    res1 = q.get()
    print(res1)
    res2 = q.get()
    print(res2)
    print(res1+res2)
```
###  效率对比
```
import time
import multiprocessing 
import threading

def _cost_time(func):
    def warpper(*args,**kw):
        start_time = time.time()
        func(*args,**kw)
        end_time = time.time()
        print('cost time :',end_time - start_time)
    return warpper
    

def job(q):
    res = 0
    for i in range(1000000):
        res += i + i**2 + i**3
    q.put(res) # queue

@_cost_time
def normal():
    res = 0
    for _ in range(2):
        for i in range(1000000):
            res += i + i**2 + i**3
    print('normal:', res)
    

@_cost_time
def multithread():
    q = multiprocessing.Queue() 
    t1 = threading.Thread(target=job, args=(q,))
    t2 = threading.Thread(target=job, args=(q,))
    t1.start()
    t2.start()
    t1.join()
    t2.join()
    res1 = q.get()
    res2 = q.get()
    print('multithread:', res1 + res2)


@_cost_time
def multicore():
    q =  multiprocessing.Queue()
    p1 = multiprocessing .Process(target=job, args=(q,))
    p2 =  multiprocessing .Process(target=job, args=(q,))
    p1.start()
    p2.start()
    p1.join()
    p2.join()
    res1 = q.get()
    res2 = q.get()
    print('multicore:',res1 + res2)


normal()
multithread()
multicore()
```
打印结果
```
('normal:', 499999666667166666000000L)
('cost time :', 0.8630490303039551)
('multithread:', 499999666667166666000000L)
('cost time :', 1.8854999542236328)
('multicore:', 499999666667166666000000L)
('cost time :', 0.47038793563842773)
```
耗时 `多进程 < 普通 < 多线程` 。

多线程不适合计算密集型

## 进程池
1. Pool默认调用是CPU的核数，传入processes参数可自定义CPU核数
2. map() 放入迭代参数，返回多个结果
3. apply_async()只能放入一组参数，并返回一个结果，如果想得到map()的效果需要通过迭代


```
import multiprocessing 

def job(x):
    return x*x

def multicore():
    pool = multiprocessing.Pool(processes=3)     # processes=3  定义CPU核数量为3
    res = pool.map(job, range(10))  # map()中需要放入函数和需要迭代运算的值，然后它会自动分配给CPU核，返回结果
    print(res)
    res = pool.apply_async(job, (3,)) # 只能传一个值，且是可迭代的
    print(res.get())  # 获得返回值
    multi_res =[pool.apply_async(job, (i,)) for i in range(10)]
    print([res.get() for res in multi_res])

if __name__ == '__main__':
    multicore()
```

## lock
不加锁
```
import multiprocessing as mp
import time

def job(v, num):
    for _ in range(5):
        time.sleep(0.1) # 暂停0.1秒，让输出效果更明显
        v.value += num # v.value获取共享变量值
        print(v.value, end="")
        
def multicore():
    v = mp.Value('i', 0) # 定义共享变量
    p1 = mp.Process(target=job, args=(v,1))
    p2 = mp.Process(target=job, args=(v,3)) # 设定不同的number看如何抢夺内存
    p1.start()
    p2.start()
    p1.join()
    p2.join()
    
if __name__ == '__main__':
    multicore()   # 结果  145891213161720
```
加锁
```
import multiprocessing as mp
import time

def job(v, num, l):
    l.acquire() # 锁住
    for _ in range(5):
        time.sleep(0.1) 
        v.value += num # 获取共享内存
        print(v.value)
    l.release() # 释放

def multicore():
    l = mp.Lock() # 定义一个进程锁
    v = mp.Value('i', 0) # 定义共享内存
    p1 = mp.Process(target=job, args=(v,1,l)) # 需要将lock传入
    p2 = mp.Process(target=job, args=(v,3,l)) 
    p1.start()
    p2.start()
    p1.join()
    p2.join()

if __name__ == '__main__':
    multicore()
```
打印结果
```
1
2
3
4
5
8
11
14
17
20
```
